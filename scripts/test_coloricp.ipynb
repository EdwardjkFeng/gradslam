{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gradslam related modules\n",
    "import gradslam as gs\n",
    "from gradslam import Pointclouds, RGBDImages\n",
    "from gradslam.datasets import Cofusion\n",
    "from gradslam.slam import PointFusion, ICPSLAM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "torch.cuda.empty_cache() # clean cuda cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 3 #212\n",
    "\n",
    "data_set = 'CoFusion'\n",
    "\n",
    "data_path = '/home/jingkun/Dataset/'\n",
    "cofusion_path = data_path + 'CoFusion/'\n",
    "\n",
    "sequences = (\"room4-full\",)\n",
    "\n",
    "# Load data\n",
    "dataset = Cofusion(basedir= cofusion_path, sequences=sequences, seqlen=n_frames, dilation=3, start=600, height=240, width=320)\n",
    "\n",
    "loader = DataLoader(dataset=dataset, batch_size=1)\n",
    "colors, depths, intrinsics, poses, _, names = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"colors shape: {colors.shape}\")  # torch.Size([2, 8, 240, 320, 3])\n",
    "print(f\"depths shape: {depths.shape}\")  # torch.Size([2, 8, 240, 320, 1])\n",
    "print(f\"intrinsics shape: {intrinsics.shape}\")  # torch.Size([2, 1, 4, 4])\n",
    "print(f\"poses shape: {poses.shape}\")  # torch.Size([2, 8, 4, 4])\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RGB-D image objects \n",
    "rgbdimages = RGBDImages(colors.requires_grad_(False),\n",
    "                        depths.requires_grad_(False), \n",
    "                        intrinsics.requires_grad_(False),\n",
    "                        poses.requires_grad_(False),\n",
    "                        )\n",
    "\n",
    "print(rgbdimages.shape)\n",
    "\n",
    "rgbdimages.plotly(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_usage()\n",
    "del loader, colors, depths, poses, intrinsics\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse point clouds\n",
    "list_t_frame = []\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device \", device)\n",
    "slam = ICPSLAM(odom='coloricp', dsratio=3, lambda_geometric=1, device=device).requires_grad_(False)\n",
    "\n",
    "pcds = Pointclouds(device=device)\n",
    "batch_size, seq_len = rgbdimages.shape[:2]\n",
    "initial_poses = torch.eye(4, device=device).view(1, 1, 4, 4).repeat(batch_size, 1, 1, 1)\n",
    "prev_frame = None\n",
    "poses = []\n",
    "\n",
    "for s in range(seq_len):\n",
    "    start = time.time()\n",
    "    live_frame = rgbdimages[:, s].to(device)\n",
    "    if s == 0 and live_frame.poses is None:\n",
    "        live_frame.poses = initial_poses\n",
    "    pcds, live_frame.poses = slam.step(pcds, live_frame, prev_frame, inplace=False)\n",
    "\n",
    "    poses.append(live_frame.poses.cpu().detach().squeeze().numpy())\n",
    "    \n",
    "    prev_frame = live_frame if slam.odom != 'gt' else None\n",
    "\n",
    "    list_t_frame.append((time.time() - start))\n",
    "    print(\"Frame: %d, Time: %.3f\" % (s, list_t_frame[-1]))\n",
    "    print(\"Estimated pose: \", poses[s])\n",
    "\n",
    "    del live_frame\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "o3d.visualization.draw_geometries([pcds.open3d(0, max_num_points=n_frames*100000)])\n",
    "\n",
    "# Plot graph of consumed time per frame\n",
    "plt.plot(list_t_frame)\n",
    "plt.ylabel('Consumed time per frame [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pcds.has_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.io.write_point_cloud(\"../results/room4-static-gt.pcd\", pcds.open3d(0, max_num_points=None), compressed=True)\n",
    "# del pcds\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static_pcd = o3d.io.read_point_cloud(\"/home/jingkun/Dataset/CoFusion/room4-noise.klg-export/cloud-0.ply\")\n",
    "# pcd1 = o3d.io.read_point_cloud(\"/home/jingkun/Dataset/CoFusion/room4-noise.klg-export/cloud-1.ply\")\n",
    "# pcd2 = o3d.io.read_point_cloud(\"/home/jingkun/Dataset/CoFusion/room4-noise.klg-export/cloud-2.ply\")\n",
    "# pcd3 = o3d.io.read_point_cloud(\"/home/jingkun/Dataset/CoFusion/room4-noise.klg-export/cloud-3.ply\")\n",
    "# o3d.visualization.draw_geometries([static_pcd, pcd1, pcd2, pcd3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icl_pcd = o3d.io.read_point_cloud(\"../results/room4-noise-static-gt.pcd\")\n",
    "# o3d.visualization.draw_geometries([icl_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_mat_to_quat(rot_mat: np.ndarray, isprecise: bool = False):\n",
    "    M = np.array(rot_mat, dtype=np.float64, copy=False)[:4, :4]\n",
    "    if isprecise:\n",
    "        q = np.empty((4, ))\n",
    "        t = np.trace(M)\n",
    "        if t > M[3, 3]:\n",
    "            q[0] = t\n",
    "            q[3] = M[1, 0] - M[0, 1]\n",
    "            q[2] = M[0, 2] - M[2, 0]\n",
    "            q[1] = M[2, 1] - M[1, 2]\n",
    "        else:\n",
    "            i, j, k = 1, 2, 3\n",
    "            if M[1, 1] > M[0, 0]:\n",
    "                i, j, k = 2, 3, 1\n",
    "            if M[2, 2] > M[i, i]:\n",
    "                i, j, k = 3, 1, 2\n",
    "            t = M[i, i] - (M[j, j] + M[k, k]) + M[3, 3]\n",
    "            q[i] = t\n",
    "            q[j] = M[i, j] + M[j, i]\n",
    "            q[k] = M[k, i] + M[i, k]\n",
    "            q[3] = M[k, j] - M[j, k]\n",
    "        q *= 0.5 / np.sqrt(t * M[3, 3])\n",
    "    else:\n",
    "        m00, m01, m02, m10, m11, m12, m20, m21, m22 = [entry for entry in M[:3, :3].reshape(-1)]\n",
    "        K = np.array([[m00-m11-m22, 0.0, 0.0, 0.0],\n",
    "                      [m01+m10, m11-m00-m22, 0.0, 0.0],\n",
    "                      [m02+m20, m12+m21, m22-m00-m11, 0.0],\n",
    "                      [m21-m12, m02-m20, m10-m01, m00+m11+m22]])\n",
    "        K /= 3.0\n",
    "        # Quaternion is eignevector of K that corresponds to largest eigenvalue\n",
    "        w, V = np.linalg.eigh(K)\n",
    "        # q = [x, y, z, w]\n",
    "        q = V[[0, 1, 2, 3], np.argmax(w)]\n",
    "    if q[3] < 0.0:\n",
    "        np.negative(q, q)\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_qt = []\n",
    "# np.set_printoptions(suppress=True, formatter={'float_kind':'{:0.4f}'.format})\n",
    "for i in range(len(poses)):\n",
    "    pose = poses[i]\n",
    "    t = pose[:3, 3].reshape(-1)\n",
    "    rot_mat = np.identity(4)\n",
    "    rot_mat[:3, :3] = pose[:3, :3]\n",
    "    qt = rotation_mat_to_quat(rot_mat).reshape(-1)\n",
    "    poses_qt.append(np.append(t, qt).astype(np.float16))\n",
    "\n",
    "names_list = names[0].strip().split(\", \")\n",
    "\n",
    "with open(\"../results/room4-gt.txt\", \"w\") as f:\n",
    "    for i in range(len(names_list)):\n",
    "        outstr = names_list[i][11:]\n",
    "        # TODO\n",
    "        for j in range(len(poses_qt[i])):\n",
    "            outstr += \" \"\n",
    "            outstr += \"{:f}\".format(poses_qt[i][j])\n",
    "        # pose_str = ' '.join(map(str, poses_qt[i]))\n",
    "        # pose_str = np.savetxt(sys.stdout, poses_qt[i], newline=' ', fmt=\"%.4f\")\n",
    "        f.write(outstr + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "torch.cuda.empty_cache() # clean cuda cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "slam = ICPSLAM(device=device)\n",
    "pointclouds, recovered_poses = slam(rgbdimages)\n",
    "o3d.visualization.draw_geometries([pointclouds.open3d(0, max_num_points=None)])\n",
    "\n",
    "print(recovered_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cuda cache\n",
    "del pcds\n",
    "del slam\n",
    "del rgbdimages\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() # clean cuda cache\n",
    "\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plotly_map_update_visualization(intermediate_pcs, poses, K, max_points_per_pc = 50000, ms_per_frame = 50):\n",
    "    def plotly_poses(poses, K):\n",
    "        fx = abs(K[0, 0])\n",
    "        fy = abs(K[1, 1])\n",
    "        f = (fx + fy) / 2\n",
    "        cx = K[0, 2]\n",
    "        cy = K[1, 2]\n",
    "\n",
    "        cx = cx / f\n",
    "        cy = cy / f\n",
    "        f = 1.\n",
    "\n",
    "        pos_0 = np.array([0., 0., 0.])\n",
    "        fustum_0 = np.array(\n",
    "            [\n",
    "                [-cx, -cy, f],\n",
    "                [cx, -cy, f],\n",
    "                list(pos_0),\n",
    "                [-cx, -cy, f],\n",
    "                [-cx, cy, f],\n",
    "                list(pos_0),\n",
    "                [cx, cy, f],\n",
    "                [-cx, cy, f],\n",
    "                [cx, cy, f],\n",
    "                [cx, -cy, f]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        traj = []\n",
    "        traj_fustums = []\n",
    "        for pose in poses:\n",
    "            rot = pose[:3, :3]\n",
    "            tvec = pose[:3, 3]\n",
    "\n",
    "            fustum_i = fustum_0 @ rot.T\n",
    "            fustum_i = fustum_i + tvec\n",
    "            pos_i = pos_0 + tvec\n",
    "\n",
    "            pos_i = np.round(pos_i, decimals=2)\n",
    "            fustum_i = np.round(fustum_i, decimals=2)\n",
    "\n",
    "            traj.append(pos_i)\n",
    "            traj_array = np.array(traj)\n",
    "            traj_fustum = [\n",
    "                go.Scatter3d(\n",
    "                    x=fustum_i[:, 0], y=fustum_i[:, 1], z=fustum_i[:, 2],\n",
    "                    marker=dict(\n",
    "                        size=0.1\n",
    "                    ),\n",
    "                    line=dict(color='purple', width=2)\n",
    "                ),\n",
    "                go.Scatter3d(\n",
    "                    x=pos_i[None, 0], y=pos_i[None, 1], z=pos_i[None, 2],\n",
    "                    marker=dict(size=0, color='purple')\n",
    "                ),\n",
    "                go.Scatter3d(\n",
    "                    x=traj_array[:, 0], y=traj_array[:, 1], z=traj_array[:, 2],\n",
    "                    marker=dict(size=0.1),\n",
    "                    line=dict(color ='purple', width=2)\n",
    "                )\n",
    "            ]\n",
    "            traj_fustums.append(traj_fustum)\n",
    "        return traj_fustums\n",
    "        \n",
    "    def frame_args(duration):\n",
    "        return {\n",
    "            \"frame\": {\"duration\": duration, \"redraw\": True},\n",
    "            \"mode\": \"immediate\",\n",
    "            \"fromcurrent\": True,\n",
    "            \"transistion\": {\"duration\": duration, \"easing\": \"linear\"}\n",
    "        }\n",
    "\n",
    "    # visualization\n",
    "    scatter3d_list = [pc.plotly(0, as_figure=False, max_num_points=max_points_per_pc) for pc in intermediate_pcs]\n",
    "    traj_frustums = plotly_poses(poses.cpu().numpy(), K.cpu().numpy())\n",
    "    data = [[*frustum, scatter3d] for frustum, scatter3d in zip(traj_frustums, scatter3d_list)]\n",
    "\n",
    "    steps = [\n",
    "        {\"args\": [[i], frame_args(0)], \"label\": i, \"method\": \"animate\"}\n",
    "        for i in range(seq_len)\n",
    "    ]\n",
    "    sliders = [\n",
    "        {\n",
    "            \"active\": 0,\n",
    "            \"yanchor\": \"top\",\n",
    "            \"xanchor\": \"left\",\n",
    "            \"currentvalue\": {\"prefix\": \"Frame: \"},\n",
    "            \"pad\": {\"b\": 10, \"t\": 60},\n",
    "            \"len\": 0.9,\n",
    "            \"x\": 0.1,\n",
    "            \"y\": 0,\n",
    "            \"steps\": steps,\n",
    "        }\n",
    "    ]\n",
    "    updatemenus = [\n",
    "        {\n",
    "            \"buttons\": [\n",
    "                {\n",
    "                    \"args\": [None, frame_args(ms_per_frame)],\n",
    "                    \"label\": \"&#9654;\",\n",
    "                    \"method\": \"animate\",\n",
    "                },\n",
    "                {\n",
    "                    \"args\": [[None], frame_args(0)],\n",
    "                    \"label\": \"&#9724;\",\n",
    "                    \"method\": \"animate\",\n",
    "                },\n",
    "            ],\n",
    "            \"direction\": \"left\",\n",
    "            \"pad\": {\"r\": 10, \"t\": 70},\n",
    "            \"showactive\": False,\n",
    "            \"type\": \"buttons\",\n",
    "            \"x\": 0.1,\n",
    "            \"xanchor\": \"right\",\n",
    "            \"y\": 0,\n",
    "            \"yanchor\": \"top\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    frames = [{\"data\": frame, \"name\": i} for i, frame in enumerate(data)]\n",
    "    fig.add_traces(frames[0][\"data\"])\n",
    "    fig.update(frames=frames)\n",
    "    fig.update_layout(\n",
    "        updatemenus=updatemenus,\n",
    "        sliders=sliders,\n",
    "        showlegend=False,\n",
    "        scene=dict(\n",
    "            xaxis=dict(showticklabels=False, showgrid=False, zeroline=False, visible=False,),\n",
    "            yaxis=dict(showticklabels=False, showgrid=False, zeroline=False, visible=False,),\n",
    "            zaxis=dict(showticklabels=False, showgrid=False, zeroline=False, visible=False,),\n",
    "        ),\n",
    "        height=600, width=400\n",
    "    )\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUM(tum_path, seqlen=20, dilation=19, height=480, width=640)\n",
    "loader = DataLoader(dataset=dataset, batch_size=1)\n",
    "colors, depths, intrinsics, poses, *_ = next(iter(loader))\n",
    "\n",
    "# create rgbdimages object\n",
    "rgbdimages = RGBDImages(colors, depths, intrinsics, poses)\n",
    "\n",
    "# step by step SLAM and store intermediate maps\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "slam = PointFusion(odom='gt', device=device)  # use gt poses because large dilation (small fps) makes ICP difficult\n",
    "pointclouds = Pointclouds(device=device)\n",
    "batch_size, seq_len = rgbdimages.shape[:2]\n",
    "initial_poses = torch.eye(4, device=device).view(1, 1, 4, 4).repeat(batch_size, 1, 1, 1)\n",
    "prev_frame = None\n",
    "intermediate_pcs = []\n",
    "for s in range(seq_len):\n",
    "    live_frame = rgbdimages[:, s].to(device)\n",
    "    if s == 0 and live_frame.poses is None:\n",
    "        live_frame.poses = initial_poses\n",
    "    pointclouds, live_frame.poses = slam.step(pointclouds, live_frame, prev_frame)\n",
    "    prev_frame = live_frame if slam.odom != 'gt' else None\n",
    "    intermediate_pcs.append(pointclouds[0])\n",
    "\n",
    "# visualize\n",
    "rgbdimages.plotly(0).update_layout(autosize=False, height=600, width=400).show()\n",
    "fig = plotly_map_update_visualization(intermediate_pcs, poses[0], intrinsics[0, 0], 15000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('gradslam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2af38f6cc3291ded760641bf70a2ae3a2429ff6fd74efc4a1fe07b0e8ccb3a34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
